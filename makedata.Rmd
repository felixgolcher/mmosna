---
title: "Exercise for Linear General Mixed Models"
author: "Felix Golcher"
date: "`r format(Sys.time(), '%d %B, %Y %H:%M')`"
bibliography: [packages.bib, glmm.bib]
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: true
    fig_caption: yes
    table_caption: yes
    df_print: "paged"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      autodep = TRUE,
                      message = FALSE,
                      warning = FALSE)
knitr::write_bib(file = 'packages.bib')
inputpath <- "data/"
outputpath <- inputpath
contr.sum.flx <- function(n, contrasts = TRUE, sparse = FALSE) 
{
    if (length(n) <= 1L) {
        if (is.numeric(n) && length(n) == 1L && n > 1L) 
            levels <- seq_len(n)
        else stop("not enough degrees of freedom to define contrasts")
    }
    else levels <- n
    levels <- as.character(levels)
    cont <- diag(length(levels))
    if (contrasts) {
        cont <- cont[, -length(levels), drop = FALSE]
        cont[length(levels), ] <- -1
        colnames(cont) <- levels[-length(levels)]
    }
    cont
}
options(contrasts = c(unordered = "contr.sum.flx",
                          ordered= "contr.poly"))

# devtools, I think does not run on windows machine without effor (rTools).
# Install devtools package if necessary
# if(!"devtools" %in% rownames(installed.packages()))
#   install.packages("devtools")

# Install the latest development snapshot from GitHub
# if(!"papaja" %in% rownames(installed.packages())) 
#  devtools::install_github("crsh/papaja@devel")
library(nloptr)
## from https://github.com/lme4/lme4/issues/98:
defaultControl <- list(algorithm="NLOPT_LN_BOBYQA",xtol_rel=1e-6,maxeval=1e5)
nloptwrap2 <- function(fn,par,lower,upper,control=list(),...) {
    for (n in names(defaultControl)) 
      if (is.null(control[[n]])) control[[n]] <- defaultControl[[n]]
    res <- nloptr(x0=par,eval_f=fn,lb=lower,ub=upper,opts=control,...)
    with(res,list(par=solution,
                  fval=objective,
                  feval=iterations,
                  conv=if (status>0) 0 else status,
                  message=message))
}
```

```{r packages, include=FALSE, cache=FALSE}
library(readxl)
library(gridExtra)
library(openxlsx)
library(ggrepel)
library(tidyverse)
library(ggplot2)
library(emmeans)
library(Hmisc)
library(scales)
library(qqplotr)
library(lme4)
library(optimx)
library(nloptr)
library(effects)
# library(papaja)
library(sjPlot)
library(sjlabelled)
library(kableExtra)
library(knitr)
knit_hooks$set(inline =
  function (x) {
      if (is.numeric(x)) {
          x = round(x, getOption("digits"))
          if (x < 1 & x > -1) {
            x = sub("0\\.","\\.",as.character(x)) 
          }

      }
      paste(as.character(x), collapse = ", ")
      }
  )
write_bib(x = .packages(), file="packages.bib")
theme_set(theme_minimal())# +
  # theme(text = element_text(size=3))
tab_model <- function(...){
  sjPlot::tab_model(collapse.ci = T,
                    linebreak = T,
                    digits.p = 3, # not smaller, since bug https://github.com/strengejacke/sjPlot/issues/789
                    show.intercept = F,
                    p.style = "numeric", # numeric seems broken.
                    show.icc = F,
                    show.obs = F,
                    show.ngroups = F,
                    ci.hyphen = ",",
                    ...)#, title = title, collapse.ci = collapse.ci,
                    #linebreak = linebreak, digits.p = digits.p#,
                    # works somehow in the wrong way.
                    # file = paste0(deparse(substitute(...)),".html")
                    #)
}
# at the moment tailored for plotting Situation effect plots.
# we need something more flex. if we want to plot other vars.
ploteff <- function(mod,
                    levels = Sit[sitseq]){
  siteff <- allEffects(mod)$Situation
  siteff %>%
    as_tibble() %>% 
    mutate(across(where(is.numeric), ~ ./exp(siteff$offset)), # siteff = 0 for binom
           Situation = factor(Situation, 
                              levels = levels)) -> sitdat
  ggplot(sitdat, aes(Situation, fit, ymin=lower, ymax=upper))+
    geom_point(size=2)+
    geom_errorbar(width=.4)+
    scale_y_continuous(ifelse(family(mod)$family == "poisson",
                         "Estimated Rate of Occurrence",
                         "Estimated Probability of Occurrence"))+
    coord_trans(y = family(mod)$link)
}
labelcol <- function(v){
  v <- set_label(v,labelmap[cur_column()])
  if(!is.numeric(v)){
    v <- sjlabelled::as_factor(v)
  }
  v
}
ppp <- function(x){
  if(x<.001){
    "<.001"
  } else {
    paste0(" = ",signif(x,1))
  }
}
```

The data are described in the [readme of the data directory](https://scm.cms.hu-berlin.de/golchefe/reflex-pipeline/-/tree/master/data).

### Figure dimensions

The figure width is *globally* set in this code 

```{r}
knitr::opts_chunk$set(fig.width = (myfw <- 7),
                      fig.height = myfw/2)
```


# Prep

## Configure Names

```{r}
Sit <- c(
  A="E-Mail/pupil",
  C="E-Mail/L2 student",
  B="Exam task",
  D="Tutorial task")
sitseq <- c("A","C","B","D")
quest <- c(
  d="that",
  w="while",
  s="there",
  t="dance"
)
```



## read in meta data

```{r}
(read_excel(file.path(inputpath, "meta_perso.xlsx"),
           sheet = 1,
           .name_repair = "universal") -> meta_perso.raw) %>% 
  select(-Studie,
         -GT2_tasks_pc, # perf corr with GT2_corr_items
         -GT_items_pc, # similar
         -PerCent_GT2, # ...
         -PerCent_GT1,
         -PerCent_all
         ) %>% 
  mutate(Akad_Fam = as.character(c("non academic","academic")[Akad_Fam+1])) %>% 
  rename(Datum_start = Datum) -> meta_perso_2
```

Das Datum in `data/ReFlex_2020_Metadaten_Hauptstudie.xlsx` ist der Zeitpunkt der demographischen Daten, die die erste Aufgabe in der Studie darstellen. Somit markiert es den Beginn der Studie, f체r die die TN 3 Wochen Zeit hatten. In der Tabelle `data/ReFlex_2020_Qualitative_Bewertung_der_Erkl채rungen_Hauptstudie.xlsx` beziehen sich Datumsangaben auf die Erstellungstage der einzelnen Erkl채rungen.

```{r} 
(read_excel(file.path(inputpath, "meta_perso.xlsx"),
           sheet = 2,
           .name_repair = "universal") -> meta_perso_meta.raw) %>% 
  filter(!is.na(Bezeichnung_Plot),
         !as.character(Bezeichnung_Plot) %in% 0:10 # Right now, there are numbers interspersed
         ) -> meta_perso_meta
stopifnot(sum(!meta_perso_meta$Variable %in% names(meta_perso_2)) == 0)
labelmap <-meta_perso_meta$Bezeichnung_Plot
names(labelmap) <- meta_perso_meta$Variable

meta_perso_2 %>% 
  mutate(across(meta_perso_meta$Variable,
                labelcol
  )) -> meta_perso
```


## read 2nd meta data file

```{r}
(read_excel(file.path(inputpath, "meta_quali.xlsx"),
            sheet = 1,
           .name_repair = "universal") -> meta_quali.raw) %>% 
  mutate(Correctness_score = ifelse(Correctness_score == 11,
                                    NA,
                                    Correctness_score),
         Mixed_expanation = ifelse(Mixed_expanation == 9,
                                    NA,
                                    Mixed_expanation),
         Sem_explanation = ifelse(Sem_explanation == 9,
                                    NA,
                                    Sem_explanation),
         Explanation_type = ifelse(Explanation_type == 9,
                                    NA,
                                    Explanation_type))-> meta_quali_2
```

```{r} 
(read_excel(file.path(inputpath,
                      "meta_quali.xlsx"),
           sheet = 2,
           .name_repair = "universal") -> meta_quali_meta.raw) %>% 
  filter(!is.na(Bezeichnung_Plot),
         !as.character(Bezeichnung_Plot) %in% 0:10 # Right now, there are numbers interspersed
         ) -> meta_quali_meta
stopifnot(sum(!meta_quali_meta$Variable %in% names(meta_quali_2)) == 0)
labelmap <-meta_quali_meta$Bezeichnung_Plot
names(labelmap) <- meta_quali_meta$Variable

meta_quali_2 %>% 
  mutate(across(meta_quali_meta$Variable,
                labelcol
  )) -> meta_quali
```

```{r}
meta <- full_join(meta_perso, meta_quali)
if(nrow(meta) != nrow(meta_quali)){
  warning("The number of rows in the joined meta data (",
          nrow(meta),
          ") is not equal to the number of rows in the
qualitative meta data (",nrow(meta_quali),") as it should be.")
}
```


## read in main data and join with meta data

```{r, warning=TRUE, cache=FALSE}
(read_excel(file.path(inputpath, "main.xlsx"),
            sheet = 1,
           .name_repair = "universal") -> dta.raw) %>% 
  rename_all(~ gsub("\\.+","_",.)) %>% 
  select(-starts_with("..")) %>% 
  filter(!is.na(Situation))-> dta.halfcooked
full_join(dta.halfcooked,
          meta) -> meta.joined

if(nrow(dta.halfcooked) != nrow(meta.joined)){
  warning("merging did not completely work!\n only in meta: ",
          unique(meta$TN_ID)[! unique(meta$TN_ID) %in% unique(dta.halfcooked$TN_ID)],
          "\n only in data: ", 
          unique(dta.halfcooked$TN_ID)[! unique(dta.halfcooked$TN_ID) %in% unique(meta$TN_ID)])
}
meta.joined %>% 
  select(-LingAufgabe # same as "Situation"
         ) %>% 
  filter(Anf == 1, ## filter out non beginners
         !is.na(Document) ## filter out merging errors.
         ) %>% 
  mutate(Kohorte = factor(Kohorte),
         Situation_orig = Situation,
         Situation = factor(Situation, 
                            levels = sitseq,
                            labels = Sit[sitseq]),
         Question = quest[Question],
         sex = factor(c("male","female")[sex]),
         Sem_explanation = as.character(c("yes","no")[Sem_explanation+1]))-> dta
```

Die ausgeschlossenen Personen (`r length(unique(dta.raw$TN.ID[!is.na(dta.raw$TN.ID)]))-length(unique(dta$TN_ID))`) hatten bereits ein oder beide linguistische Module abgeschlossen haben und sind somit keine Anf채nger mehr.

## read in 2nd sheet from main data file

There we have descriptions of variables and information about the norm measure.

```{r}
read_excel(file.path(inputpath, "main.xlsx"),
            sheet = 2,
           .name_repair = "universal",
           na = c("keine")) %>% 
  mutate(Normalisierung = factor(Normalisierung,
                                 levels = c("N_Clauses",
                                            "Words",
                                            "sentences")),
         Variablenname = vctrs::vec_as_names(Variablenname,
                                             repair = "universal"),
         Variablenname = gsub("\\.+","_",Variablenname)) -> mapping
stopifnot(nrow(mapping) == ncol(dta.halfcooked))
stopifnot(length(mapping$Variablenname[!mapping$Variablenname %in% colnames(dta)]) == 1) # LingAufgabe 
stopifnot(length(colnames(dta.halfcooked)[!colnames(dta.halfcooked) %in% mapping$Variablenname])==0) # Clauses

mapper <- mapping %>% filter(!is.na(Normalisierung))

nmap = as.character(mapper$Normalisierung)
names(nmap) <- as.character(mapper$Variablenname)

dta %>%
  mutate(across(names(nmap[nmap == "N_Clauses"]),
                list(norm_clauses = ~./N_Clauses),
                .names = "{col}_{fn}")) %>% 
  mutate(across(names(nmap[nmap == "Words"]),
                list(norm_tokens = ~./Words),
                .names = "{col}_{fn}")) %>% 
  mutate(across(names(nmap[nmap == "sentences"]),
                list(norm_sentences = ~./Sentences_total_),
                .names = "{col}_{fn}")) %>%
  mutate(across(contains("_norm_"),
                list(scaled = ~ (. - mean(., na.rm=T))/sd(., na.rm=T)),
                .names = "{col}_{fn}")) %>% 
  select(TN_ID, Situation, Words, N_Clauses, Sentences_total_, everything()) %>% 
  select(-Nr, -Document, -Kohorte, -Question, everything())-> dte2
```

```{r}
(mapping %>% 
  filter(!is.na(Bezeichnung_Plot))->lmn) %>% 
  pull(Bezeichnung_Plot) -> labelmap
names(labelmap) <- lmn$Variablenname

dte2 %>% 
  mutate(across(names(labelmap),
                labelcol
  )) -> dte
```



We have 

* `r nrow(dta)` rows in `r ncol(dta)` Spalten in `dta` and 
* `r nrow(dte)` rows in `r ncol(dte)` Spalten in the normed data `dte`.


```{r}
dte %>% 
  filter(Anf_Fort == 1,
         Expl_given == 1) -> dtr
```

```{r}
dtr %>% 
  filter(!is.na(Abi)) %>% 
  mutate(TaskCompliance = set_label(ifelse(Correctness_score > 0,
                                           "Yes", "No"),
                                    "Task Compliance")) -> dtr.abi
```


w0 <- lmer(sqrt(Words) ~ Abi + Situation + (1|TN_ID), data=dtr.abi)

```{r}
dtr.abi %>%
  select(TN_ID, Words, Situation, Question, Correctness_score) %>% 
  write.xlsx("data/LengthInWords.xlsx", overwrite = T)
dtr.abi %>% 
  select(TN_ID, Abi, Age, sex, GT_points) %>% 
  distinct() %>% 
  write.xlsx("data/LengthInWords-meta.xlsx",
             overwrite = T)
```

