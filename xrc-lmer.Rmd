---
title: "Exercise for Linear General Mixed Models"
author: "Felix Golcher"
date: "`r format(Sys.time(), '%d %B, %Y %H:%M')`"
bibliography: [packages.bib]
output:
  bookdown::html_document2:
    toc: true
    toc_float: true
    toc_depth: 6
    number_sections: true
    fig_caption: yes
    table_caption: yes
    df_print: "paged"
---


```{r setup, include=FALSE}
## It's not necessary that you understand the code in this block.
## It's just convenient stuff and maybe nice to see.

## Some defaults how to render the output doc
knitr::opts_chunk$set(cache = TRUE, ## remember old computations, can _vastly_ reduce computation time.
                      autodep = TRUE, ## recompute dependent chunks
                      message = FALSE, ## do not write messages to the output document
                      warning = FALSE, ## dito with warnings
                      fig.width = (myfw <- 7), ## default width of figures
                      fig.height = myfw/2) ## make figures half as high as they are wide.
inputpath <- "data/" ## where to find the data
outputpath <- inputpath ## where to write

## you might want to change default contrasts
# options(contrasts = c(unordered = "contr.sum",
#                           ordered= "contr.poly"))

```

```{r packages, include=FALSE, cache=FALSE}
## maybe you don't _need_ all those:
library(readxl)
library(gridExtra)
# library(ggrepel)
library(tidyverse)
# library(ggplot2)
# library(emmeans)
library(Hmisc)
library(scales)
library(GGally)
library(qqplotr)
library(lme4)
library(lmerTest)
# library(optimx)
# library(nloptr)
library(effects)
# library(papaja)
library(sjPlot)
library(sjlabelled)
library(kableExtra)
library(knitr)
## if you don't want to render 0.001 as .001 remove this hook:
knit_hooks$set(inline =
  function (x) {
      if (is.numeric(x)) {
          x = round(x, getOption("digits"))
          if (x < 1 & x > -1) {
            x = sub("0\\.","\\.",as.character(x)) 
          }

      }
      paste(as.character(x), collapse = ", ")
      }
  )
## write a bib file for each loaded package:
## now you can cite package lme4 as @R-lme4.
## It's nice to cite packages: People get the cred they deserve and
## readers know what you were using.
write_bib(x = .packages(), file="packages.bib")
## plots light and white:
theme_set(theme_minimal())

## set som defaults
tab_model <- function(...){
  sjPlot::tab_model(collapse.ci = T,
                    linebreak = T,
                    digits.p = 3, # not smaller, since bug https://github.com/strengejacke/sjPlot/issues/789
                    show.intercept = F,
                    p.style = "numeric", # numeric seems broken.
                    show.icc = F,
                    show.obs = F,
                    show.ngroups = F,
                    ci.hyphen = ",",
                    ...)
}

# this semantics should exist, but what was it called again...
some <- function(dtx, length = 10){
    slice(dtx, as.integer(seq(1, n(), length = length)))
}
```


# Reading in the data

We have two data files

## Main data

```{r}
maindata <- read_excel("data/LengthInWords.xlsx")
maindata %>% 
  some() %>% 
  kbl() %>% 
  kable_styling()
```

* Subjects wrote texts. Each data point (line) represents one text written by one subjects.
* `TN_ID` is the subject id.
* `Situation` is one of 4 situations the subjects were confronted with. There were 2 more formal and 2 more informal ones. The design is not really $2\times 2$ since the two pairs cannot be matched.
* `Words` is the number of words the subjects produced in this situation.
* `Question` is the prompt the subjects were given.
* `Correctness_score` is a manual assessment of the texts.

## Meta data

```{r}
metadata <- read_excel("data/LengthInWords-meta.xlsx")
metadata %>% 
    some() %>% 
  kbl() %>% 
  kable_styling()
```

These variables are mostly selfexplaining. `GT_points` are points reached in some grammar test.

## Join main und meta data

```{r}
fulldata <- full_join(maindata, metadata)
stopifnot(nrow(fulldata) == nrow(maindata)) # We should have the same number of lines afterwards
stopifnot(ncol(fulldata) == ncol(maindata) + ncol(metadata) -1) # exactly on column for joining
```

# Analysis

## Research question

> Does the number of words differ between situations?

## Three variables describe something very similar

```{r, fig.cap="Funny situation: Two of the three pairs are clearly correlated, but the third pair much less."}
grid.arrange(
  ggplot(metadata, aes(GT_points, Abi))+
    geom_point()+
    geom_smooth(method="lm"),
  ggplot(fulldata, aes(GT_points, Correctness_score))+
    geom_jitter()+
    geom_smooth(method="lm"),
  ggplot(fulldata, aes(Abi, Correctness_score))+
    geom_jitter()+
    geom_smooth(method="lm"), nrow=1)
```


```{r, fig.cap="When we average over people we still have the same situation."}
my_fn <- function(data, mapping, method="lm", ...){
  p <- ggplot(data = data, mapping = mapping) + 
    geom_point() + 
    geom_smooth(method=method, ...)
  p
}
fulldata %>% 
  group_by(TN_ID) %>% 
  summarise(GT_points = first(GT_points),
            Abi = first(Abi),
            Correctness_score = mean(Correctness_score)) %>% 
  select(-TN_ID) %>% 
  ggpairs(lower = list(continuous = my_fn))
```

We will use only one of those variables. Otherwise there could be problems with interpreting the model.

## How do the data look like?

### Plot 1: Is there an effect?

Produce a plot:

* that has *situation* on the X-axis
* and Words on the Y-axis
* underlay it with boxplots.

```{r, echo=FALSE, fig.cap="I prepared something for you..."}
fulldata %>% 
  ggplot()
```

### Plot 2: Distribution

Plot the distribution of *Words*.

```{r, echo=FALSE, fig.cap="I prepared less for you..."}
```

### Plot 3: Transformations

QQ-plots show us how normally the data are distributed. Perfect data look like this:

```{r, fig.cap="QQ-Plot for perfectly normal data. You don't see those in the wild."}
tibble(x = rnorm(1e3)) %>% 
  ggplot(aes(sample = x))+
  geom_qq_band()+
  geom_qq()+
  geom_qq_line()
```

Plot QQ-Plots for

* the untransformed data
* log-transformed data: $x^\prime = \log x$ (the standard)
* $\sqrt{~~}$-transformed data: $x^\prime = \sqrt{x}$ (strangely it sometimes works)
* inverse transformed data: $x^\prime = -1/x$ (good candidate for reaction time data)


**Remark:** Actually, the residuals have to be normally distributed. But often the noise is so much larger than the effects that it's fine to check the data itself. You don't need a model for that...


## The model

Now we actually proceed with computing a mixed model. In reality we would do a lot more consistency checks on the data, more diagnostic plots and all that.

### Setup

Set up a mixed model with `lmer` from package `lme4` [@R-lme4]. Use one of the three variables `Abi`, `GT_Points` and `Correctness_score` that somehow measure the knowledge of the subjects.

```{r}
w0 <- lmer(sqrt(Words) ~ Abi + Situation + (1|TN_ID), data=fulldata)
summary(w0)
```

### Assessment

#### Residual plot

Compile a QQ-Plot for the residuals. Is it OK?

```{r, echo=FALSE, fig.cap="The Residuals look quite nice"}
data.frame(resid = resid(w0)) %>% 
  ggplot(aes(sample = scale(resid))) + ## qqband wants that... 
  geom_qq_band() +
  geom_qq()+
  geom_qq_line()
```

#### p-values

* The function `update` can and should be used to change things in a model.
* `anova` can be used to compare two nested models and to get a significance test.

```{r}
w0.reml <- update(w0, REML = T) # but anova does this automatically...
w0.reml.noabi <- update(w0.reml, .~. -Abi)
anova(w0.reml.noabi, w0.reml)
```

The result is very similar to what you saw in the model table:

```{r}
coefficients(summary(w0))["Abi",]
```

We can use the `drop1` function to remove one predictor at a time and run a significance test on it.

```{r}
drop1(update(w0, REML = F), test = "Chisq")
drop1(update(w0, .~. + Abi:Situation, REML = F), test = "Chisq")
```



```{r, fig.cap="Always look at what you did.", fig.width=8, fig.height=4}
plot(allEffects(w0))
```



```{r}
tab_model(w0)
```

### Change contrasts


```{r}
cm <- as.matrix(cbind(
  # offset
  1/4,
  # A vs B
  c(1,-1,0,0),
  # C vs D
  c(0,0,1,-1),
  # AB vd CD
  c(1/2, 1/2, -1/2, -1/2)))
cmm <- solve(t(cm))
cmn <- cmm[,-1]
colnames(cmn) <- c("Formal: A vs B","Informal: C vs D", "Formal vs Informal")
fulldata %>% 
  mutate(Situation = C(factor(Situation), contr = cmn)) -> contrdata
```

```{r}
w1 <- update(w0, data = contrdata)
```

```{r}
tab_model(w1)
```

```{r}
plot(allEffects(w1)[c(1,2)])
```

# Acknowledgement

Thanks to Milena KÃ¼hnast for the nice data set.

# packages we used

`r paste0("@R-",setdiff(.packages(), c("datasets","grDevices", "graphics", "methods", "stats", "utils")), collapse = ", ")`
